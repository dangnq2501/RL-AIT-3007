{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d94ae",
   "metadata": {
    "papermill": {
     "duration": 0.002602,
     "end_time": "2024-12-16T10:15:42.197685",
     "exception": false,
     "start_time": "2024-12-16T10:15:42.195083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14390732",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T10:15:42.203765Z",
     "iopub.status.busy": "2024-12-16T10:15:42.203011Z",
     "iopub.status.idle": "2024-12-16T10:15:42.874482Z",
     "shell.execute_reply": "2024-12-16T10:15:42.873628Z"
    },
    "papermill": {
     "duration": 0.676471,
     "end_time": "2024-12-16T10:15:42.876363",
     "exception": false,
     "start_time": "2024-12-16T10:15:42.199892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rl-parameter/trained_agent.pth\n",
      "/kaggle/input/rl-parameter/red.pt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee4ca33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:15:42.882009Z",
     "iopub.status.busy": "2024-12-16T10:15:42.881674Z",
     "iopub.status.idle": "2024-12-16T10:16:02.904108Z",
     "shell.execute_reply": "2024-12-16T10:16:02.903218Z"
    },
    "papermill": {
     "duration": 20.027307,
     "end_time": "2024-12-16T10:16:02.906039",
     "exception": false,
     "start_time": "2024-12-16T10:15:42.878732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting magent2\r\n",
      "  Downloading magent2-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from magent2) (1.26.4)\r\n",
      "Collecting pygame>=2.1.0 (from magent2)\r\n",
      "  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: pettingzoo>=1.23.1 in /opt/conda/lib/python3.10/site-packages (from magent2) (1.24.0)\r\n",
      "Requirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (2.4.0)\r\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (6.0.2)\r\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.0)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (1.6.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.12.2)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (0.11.9)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (70.0.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch_lightning) (3.1.2)\r\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from pettingzoo>=1.23.1->magent2) (0.29.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.15.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2) (3.1.0)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2) (0.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\r\n",
      "Downloading magent2-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pygame, magent2\r\n",
      "Successfully installed magent2-0.3.3 pygame-2.6.1\r\n",
      "Collecting pettingzoo==1.22.0\r\n",
      "  Downloading PettingZoo-1.22.0-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from pettingzoo==1.22.0) (1.26.4)\r\n",
      "Requirement already satisfied: gymnasium>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from pettingzoo==1.22.0) (0.29.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.26.0->pettingzoo==1.22.0) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.26.0->pettingzoo==1.22.0) (4.12.2)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.26.0->pettingzoo==1.22.0) (0.0.4)\r\n",
      "Downloading PettingZoo-1.22.0-py3-none-any.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.4/823.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pettingzoo\r\n",
      "  Attempting uninstall: pettingzoo\r\n",
      "    Found existing installation: pettingzoo 1.24.0\r\n",
      "    Uninstalling pettingzoo-1.24.0:\r\n",
      "      Successfully uninstalled pettingzoo-1.24.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle-environments 1.16.9 requires pettingzoo==1.24.0, but you have pettingzoo 1.22.0 which is incompatible.\r\n",
      "magent2 0.3.3 requires pettingzoo>=1.23.1, but you have pettingzoo 1.22.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pettingzoo-1.22.0\r\n"
     ]
    }
   ],
   "source": [
    "! pip install magent2 pytorch_lightning\n",
    "! pip install pettingzoo==1.22.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa101ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:16:02.915292Z",
     "iopub.status.busy": "2024-12-16T10:16:02.914566Z",
     "iopub.status.idle": "2024-12-16T10:16:10.037827Z",
     "shell.execute_reply": "2024-12-16T10:16:10.036907Z"
    },
    "papermill": {
     "duration": 7.130569,
     "end_time": "2024-12-16T10:16:10.040470",
     "exception": false,
     "start_time": "2024-12-16T10:16:02.909901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "class PPOActorCriticConv(nn.Module):\n",
    "    def __init__(self, input_channels, input_size, action_space_size):\n",
    "        super(PPOActorCriticConv, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),  # (input_channels x 13 x 13 -> 32 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),             # (32 x 13 x 13 -> 64 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)                              # (64 x 13 x 13 -> 64 x 6 x 6)\n",
    "        )\n",
    "        # Flatten output from Conv2D\n",
    "        conv_output_size = 64 * (input_size // 2) * (input_size // 2)  # For 13x13 input -> 64x6x6 = 2304\n",
    "\n",
    "        # Fully Connected Shared Layer\n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(conv_output_size, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Actor Head\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_space_size),\n",
    "            nn.Softmax(dim=-1)  # Output probabilities for actions\n",
    "        )\n",
    "\n",
    "        # Critic Head\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Output value of the state\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, input_channels, input_size, input_size)\n",
    "        conv_output = self.conv_layers(x)  # Convolutional layers\n",
    "        flat_output = torch.flatten(conv_output, start_dim=1)  # Flatten (batch_size, conv_output_size)\n",
    "        shared_output = self.shared_layer(flat_output)  # Shared layer\n",
    "        policy = self.actor(shared_output)  # Actor output\n",
    "        value = self.critic(shared_output)  # Critic output\n",
    "        return policy, value\n",
    "\n",
    "class PPOAgentWithLightning(pl.LightningModule):\n",
    "    def __init__(self, input_channels, input_size, action_space_size, lr=3e-4, gamma=0.99, clip_epsilon=0.2):\n",
    "        super(PPOAgentWithLightning, self).__init__()\n",
    "        self.model = PPOActorCriticConv(input_channels, input_size, action_space_size)\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.clip_epsilon = clip_epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        policy, value = self.model(x)\n",
    "        return policy, value\n",
    "\n",
    "    def compute_loss(self, batch):\n",
    "        states, actions, rewards, dones, old_policies = batch\n",
    "        policy, value = self(states)\n",
    "        value = value.squeeze(-1)\n",
    "\n",
    "        # Compute Advantage\n",
    "        returns, advantages = self.compute_advantages(rewards, value.detach(), dones)\n",
    "\n",
    "        # Compute Policy Loss\n",
    "        new_policies = policy.gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "        policy_ratio = new_policies / old_policies\n",
    "        clipped_ratio = torch.clamp(policy_ratio, 1 - self.clip_epsilon, 1 + self.clip_epsilon)\n",
    "        policy_loss = -torch.min(policy_ratio * advantages, clipped_ratio * advantages).mean()\n",
    "\n",
    "        # Compute Value Loss\n",
    "        value_loss = nn.MSELoss()(value, returns)\n",
    "\n",
    "        # Combine Losses\n",
    "        total_loss = policy_loss + 0.5 * value_loss\n",
    "        return total_loss\n",
    "\n",
    "    def compute_advantages(self, rewards, values, dones):\n",
    "        returns = []\n",
    "        advantages = []\n",
    "        G = 0\n",
    "        for r, v, d in zip(reversed(rewards), reversed(values), reversed(dones)):\n",
    "            G = r + (1 - d) * self.gamma * G\n",
    "            returns.insert(0, G)\n",
    "            advantages.insert(0, G - v)\n",
    "        returns = torch.tensor(returns, dtype=torch.float32, device=self.device)\n",
    "        advantages = torch.tensor(advantages, dtype=torch.float32, device=self.device)\n",
    "        return returns, advantages\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e69059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:16:10.054394Z",
     "iopub.status.busy": "2024-12-16T10:16:10.053936Z",
     "iopub.status.idle": "2024-12-16T10:16:10.059613Z",
     "shell.execute_reply": "2024-12-16T10:16:10.058786Z"
    },
    "papermill": {
     "duration": 0.014673,
     "end_time": "2024-12-16T10:16:10.061636",
     "exception": false,
     "start_time": "2024-12-16T10:16:10.046963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RLReplayDataset(Dataset):\n",
    "    def __init__(self, buffer):\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        state, action, reward, next_state, done, old_policy = self.buffer[idx]\n",
    "        return (\n",
    "            torch.tensor(state, dtype=torch.float32).permute(2, 0, 1),  # (channels, height, width)\n",
    "            torch.tensor(action, dtype=torch.long),\n",
    "            torch.tensor(reward, dtype=torch.float32),\n",
    "            torch.tensor(done, dtype=torch.float32),\n",
    "            torch.tensor(old_policy, dtype=torch.float32)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e8beb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:16:10.074679Z",
     "iopub.status.busy": "2024-12-16T10:16:10.074230Z",
     "iopub.status.idle": "2024-12-16T10:46:02.949905Z",
     "shell.execute_reply": "2024-12-16T10:46:02.948977Z"
    },
    "papermill": {
     "duration": 1792.889937,
     "end_time": "2024-12-16T10:46:02.957644",
     "exception": false,
     "start_time": "2024-12-16T10:16:10.067707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   0%|          | 0/40 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ef9fd93dc440cda479f617d04077ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   2%|▎         | 1/40 [01:52<1:13:15, 112.71s/it]/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/lightning_logs/version_0/checkpoints exists and is not empty.\n",
      "Training Episodes: 100%|██████████| 40/40 [29:52<00:00, 44.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from magent2.environments import battle_v4\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Initialize environment\n",
    "env = battle_v4.env(map_size=45, max_cycles=300, step_reward=0.001, attack_opponent_reward=1, dead_penalty=-0.4)\n",
    "env.reset()\n",
    "\n",
    "# Hyperparameters\n",
    "input_channels = 5\n",
    "input_size = 13\n",
    "action_space_size = 21\n",
    "lr = 3e-4\n",
    "gamma = 0.99\n",
    "clip_epsilon = 0.2\n",
    "replay_buffer = []\n",
    "max_buffer_size = 10000\n",
    "batch_size = 256\n",
    "n_episodes = 40\n",
    "\n",
    "# Initialize Lightning Module\n",
    "agent = PPOAgentWithLightning(input_channels, input_size, action_space_size, lr, gamma, clip_epsilon)\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(max_epochs=n_episodes, devices=1 if torch.cuda.is_available() else 4, accelerator='gpu' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for episode in tqdm(range(n_episodes), desc=\"Training Episodes\"):\n",
    "    env.reset()\n",
    "    episode_buffer = []\n",
    "    for agent_name in env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        team = agent_name.split('_')[0]\n",
    "\n",
    "        if termination or truncation:\n",
    "            action = None\n",
    "        else:\n",
    "            observation_tensor = torch.tensor(observation, dtype=torch.float32).permute(2, 0, 1)\n",
    "            policy, _ = agent(observation_tensor.unsqueeze(0))  # Add batch dimension\n",
    "            action = torch.multinomial(policy.squeeze(0), 1).item()\n",
    "\n",
    "            # Store transition\n",
    "            next_observation, _, _, _, _ = env.last()\n",
    "            old_policy = policy[0, action].item()\n",
    "            done = 1 if termination or truncation else 0\n",
    "            episode_buffer.append((observation, action, reward, next_observation, done, old_policy))\n",
    "\n",
    "        env.step(action)\n",
    "\n",
    "    replay_buffer.extend(episode_buffer)\n",
    "    if len(replay_buffer) > max_buffer_size:\n",
    "        replay_buffer = replay_buffer[-max_buffer_size:]\n",
    "\n",
    "    # Training step\n",
    "    if len(replay_buffer) >= batch_size:\n",
    "        dataset = RLReplayDataset(replay_buffer)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        trainer.fit(agent, dataloader)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cba565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:46:02.970145Z",
     "iopub.status.busy": "2024-12-16T10:46:02.969846Z",
     "iopub.status.idle": "2024-12-16T10:46:02.977476Z",
     "shell.execute_reply": "2024-12-16T10:46:02.976519Z"
    },
    "papermill": {
     "duration": 0.016072,
     "end_time": "2024-12-16T10:46:02.979092",
     "exception": false,
     "start_time": "2024-12-16T10:46:02.963020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pytorch_lightning as pl\n",
    "# import random\n",
    "# import os\n",
    "# from magent2.environments import battle_v4\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# class RLReplayDataset(Dataset):\n",
    "#     def __init__(self, replay_buffer):\n",
    "#         self.replay_buffer = replay_buffer\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.replay_buffer)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         state, action, reward, next_state, done = self.replay_buffer[idx]\n",
    "#         state = torch.tensor(state, dtype=torch.float32)\n",
    "#         next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "#         action = torch.tensor(action, dtype=torch.long)\n",
    "#         reward = torch.tensor(reward, dtype=torch.float32)\n",
    "#         done = torch.tensor(done, dtype=torch.float32)\n",
    "#         return state, action, reward, next_state, done\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     states_list, actions_list, rewards_list, next_states_list, dones_list = zip(*batch)\n",
    "#     states = torch.stack(states_list, dim=0)      # (B,H,W,C)\n",
    "#     next_states = torch.stack(next_states_list,0) # (B,H,W,C)\n",
    "#     actions = torch.stack(actions_list)\n",
    "#     rewards = torch.stack(rewards_list)\n",
    "#     dones = torch.stack(dones_list)\n",
    "\n",
    "#     # Để tương thích với logic cũ, ta giả lập dict {'blue': ...}\n",
    "#     return {'blue': states}, actions, rewards, {'blue': next_states}, dones\n",
    "\n",
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, stride=1):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "#         if in_channels != out_channels or stride != 1:\n",
    "#             self.shortcut = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "#                 nn.BatchNorm2d(out_channels)\n",
    "#             )\n",
    "#         else:\n",
    "#             self.shortcut = nn.Identity()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         identity = self.shortcut(x)\n",
    "#         out = self.relu(self.bn1(self.conv1(x)))\n",
    "#         out = self.bn2(self.conv2(out))\n",
    "#         out += identity\n",
    "#         out = self.relu(out)\n",
    "#         return out\n",
    "\n",
    "# class QNetwork(pl.LightningModule):\n",
    "#     def __init__(self, observation_shape=(13,13,5), action_shape=21, epsilon=0.2):\n",
    "#         super().__init__()\n",
    "#         self.save_hyperparameters()\n",
    "#         self.action_shape = action_shape\n",
    "#         self.epsilon = epsilon\n",
    "#         C = observation_shape[-1]\n",
    "#         H, W = observation_shape[0], observation_shape[1]\n",
    "\n",
    "#         # ResNet-like structure\n",
    "#         self.stage1 = nn.Sequential(\n",
    "#             ResidualBlock(C, C, stride=1),\n",
    "#             ResidualBlock(C, C, stride=1)\n",
    "#         )\n",
    "\n",
    "#         self.stage2 = nn.Sequential(\n",
    "#             ResidualBlock(C, C*2, stride=2),\n",
    "#             ResidualBlock(C*2, C*2, stride=1)\n",
    "#         )\n",
    "\n",
    "#         self.stage3 = nn.Sequential(\n",
    "#             ResidualBlock(C*2, C*4, stride=2),\n",
    "#             ResidualBlock(C*4, C*4, stride=1)\n",
    "#         )\n",
    "\n",
    "#         self.upsample = nn.Upsample(size=(H, W), mode='bilinear', align_corners=False)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             dummy_input = torch.randn(*observation_shape).permute(2,0,1).unsqueeze(0)\n",
    "#             x = self.stage1(dummy_input)\n",
    "#             x = self.stage2(x)\n",
    "#             x = self.stage3(x)\n",
    "#             x = self.upsample(x)\n",
    "#             flatten_dim = x.view(1, -1).shape[1]\n",
    "\n",
    "#         self.network = nn.Sequential(\n",
    "#             nn.Linear(flatten_dim, 120),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(120, 84),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(84, action_shape),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, obs):\n",
    "#         # obs: (B,H,W,C)\n",
    "#         obs = obs.permute(0,3,1,2).contiguous() # (B,C,H,W)\n",
    "#         x = self.stage1(obs)\n",
    "#         x = self.stage2(x)\n",
    "#         x = self.stage3(x)\n",
    "#         x = self.upsample(x)\n",
    "#         x = x.reshape(x.shape[0], -1)\n",
    "#         return self.network(x)\n",
    "\n",
    "#     def select_action(self, obs, eval_mode=False):\n",
    "#         if len(obs.shape) == 3:\n",
    "#             obs = obs.unsqueeze(0)\n",
    "#         if not eval_mode and random.random() < self.epsilon:\n",
    "#             return random.randint(0, self.action_shape - 1)\n",
    "#         with torch.no_grad():\n",
    "#             q_values = self(obs)\n",
    "#         return torch.argmax(q_values, dim=-1).item()\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         states, actions, rewards, next_states, dones = batch\n",
    "#         blue_obs = states['blue']\n",
    "#         next_blue_obs = next_states['blue']\n",
    "#         q_values = self(blue_obs)\n",
    "#         with torch.no_grad():\n",
    "#             q_values_next = self(next_blue_obs)\n",
    "#         max_next_q = q_values_next.max(dim=1)[0]\n",
    "#         target = rewards + 0.9 * max_next_q * (1 - dones)\n",
    "\n",
    "#         q_values_current = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "#         loss = nn.MSELoss()(q_values_current, target)\n",
    "#         self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return optim.Adam(self.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6370fc0",
   "metadata": {
    "papermill": {
     "duration": 0.005545,
     "end_time": "2024-12-16T10:46:02.989984",
     "exception": false,
     "start_time": "2024-12-16T10:46:02.984439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6248150,
     "sourceId": 10125506,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1826.405224,
   "end_time": "2024-12-16T10:46:06.281271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T10:15:39.876047",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11d9a7105b864062bafb345c2cf6ede0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e51ff9312e744b23b530a6e6281e035a",
       "max": 40.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5888e07cb124dfb9364bf639c19d754",
       "tabbable": null,
       "tooltip": null,
       "value": 40.0
      }
     },
     "299d57c208ca4aecb09aa413b943c90d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "547775f0ef79458f82c03639440bfd42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58b9a9842ef84bc382903af70c036e0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "99ef9fd93dc440cda479f617d04077ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c99f5240875343a0923b1311cd587582",
        "IPY_MODEL_11d9a7105b864062bafb345c2cf6ede0",
        "IPY_MODEL_f152adcdb8504291ab8f55ac7511ab9d"
       ],
       "layout": "IPY_MODEL_f4ff690790264e129a30290f70a99908",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c5888e07cb124dfb9364bf639c19d754": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c99f5240875343a0923b1311cd587582": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca1fc9b80a124f3f8cbb593d4e8ddefb",
       "placeholder": "​",
       "style": "IPY_MODEL_58b9a9842ef84bc382903af70c036e0d",
       "tabbable": null,
       "tooltip": null,
       "value": "Epoch 39: 100%"
      }
     },
     "ca1fc9b80a124f3f8cbb593d4e8ddefb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e51ff9312e744b23b530a6e6281e035a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f152adcdb8504291ab8f55ac7511ab9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_547775f0ef79458f82c03639440bfd42",
       "placeholder": "​",
       "style": "IPY_MODEL_299d57c208ca4aecb09aa413b943c90d",
       "tabbable": null,
       "tooltip": null,
       "value": " 40/40 [00:01&lt;00:00, 27.99it/s, v_num=0]"
      }
     },
     "f4ff690790264e129a30290f70a99908": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
