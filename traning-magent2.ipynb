{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10217839,"sourceType":"datasetVersion","datasetId":6248150}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":708.896485,"end_time":"2024-12-07T05:22:23.886920","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-07T05:10:34.990435","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"062ac7bc97574316bcc01affe6e851ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_a3ffe87ab8654b5e88cd20092b4c781d","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_985de08bec0c4a8c8284b7021fcbccde","tabbable":null,"tooltip":null,"value":40}},"42bfdb99f6f241f596c4b92fcfd3b487":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5f0f8c56f95845208f73919a6a558199","placeholder":"​","style":"IPY_MODEL_8c967ac6abd84da39a1bb92d68a28283","tabbable":null,"tooltip":null,"value":"Epoch 0: 100%"}},"5e0161dd7e02422bb37a0c49c8534ea7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f0f8c56f95845208f73919a6a558199":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"661faa5817c5429b99f1c45b2c97ff72":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42bfdb99f6f241f596c4b92fcfd3b487","IPY_MODEL_062ac7bc97574316bcc01affe6e851ad","IPY_MODEL_be1f5c4e420740a99a6b21ce316e2f70"],"layout":"IPY_MODEL_7ddba7ec03644301a2fd63638165a907","tabbable":null,"tooltip":null}},"7ddba7ec03644301a2fd63638165a907":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8c967ac6abd84da39a1bb92d68a28283":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"985de08bec0c4a8c8284b7021fcbccde":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3ffe87ab8654b5e88cd20092b4c781d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be1f5c4e420740a99a6b21ce316e2f70":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5e0161dd7e02422bb37a0c49c8534ea7","placeholder":"​","style":"IPY_MODEL_eda3d1901d674704ba1eea1aa95f3e4e","tabbable":null,"tooltip":null,"value":" 40/40 [00:01&lt;00:00, 25.36it/s, v_num=0]"}},"eda3d1901d674704ba1eea1aa95f3e4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"149b2271","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-12-16T15:16:37.067372Z","iopub.execute_input":"2024-12-16T15:16:37.067625Z","iopub.status.idle":"2024-12-16T15:16:38.205957Z","shell.execute_reply.started":"2024-12-16T15:16:37.067592Z","shell.execute_reply":"2024-12-16T15:16:38.205110Z"},"papermill":{"duration":0.671401,"end_time":"2024-12-07T05:10:38.003689","exception":false,"start_time":"2024-12-07T05:10:37.332288","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/trained_agent.pth\n/kaggle/input/blue_agent_14.pth\n/kaggle/input/red.pt\n/kaggle/input/blue_agent_13.pth\n","output_type":"stream"}],"execution_count":1},{"id":"8c829b01","cell_type":"code","source":"! pip install magent2 pytorch_lightning\n! pip install pettingzoo==1.22.0\n","metadata":{"execution":{"iopub.status.busy":"2024-12-16T15:16:38.207321Z","iopub.execute_input":"2024-12-16T15:16:38.207656Z"},"papermill":{"duration":19.74084,"end_time":"2024-12-07T05:10:57.746972","exception":false,"start_time":"2024-12-07T05:10:38.006132","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting magent2\n  Downloading magent2-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: numpy<2.0,>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from magent2) (1.26.4)\nCollecting pygame>=2.1.0 (from magent2)\n  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: pettingzoo>=1.23.1 in /opt/conda/lib/python3.10/site-packages (from magent2) (1.24.0)\nRequirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (2.4.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (1.6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (0.11.9)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch_lightning) (3.1.2)\nRequirement already satisfied: gymnasium>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from pettingzoo>=1.23.1->magent2) (0.29.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2) (3.1.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2) (0.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\nDownloading magent2-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pygame, magent2\nSuccessfully installed magent2-0.3.3 pygame-2.6.1\n","output_type":"stream"}],"execution_count":null},{"id":"eed38d77","cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pytorch_lightning as pl\nimport random\nimport os\nfrom magent2.environments import battle_v4\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\n\n\nclass RLReplayDataset(Dataset):\n    def __init__(self, replay_buffer):\n        self.replay_buffer = replay_buffer\n\n    def __len__(self):\n        return len(self.replay_buffer)\n\n    def __getitem__(self, idx):\n        state, action, reward, next_state, done = self.replay_buffer[idx]\n        # state, next_state: (H,W,C)\n        state = torch.tensor(state, dtype=torch.float32)\n        next_state = torch.tensor(next_state, dtype=torch.float32)\n        action = torch.tensor(action, dtype=torch.long)\n        reward = torch.tensor(reward, dtype=torch.float32)\n        done = torch.tensor(done, dtype=torch.float32)\n\n        states = state  # (H,W,C)\n        next_states = next_state\n        return states, action, reward, next_states, done\n\ndef collate_fn(batch):\n    states_list, actions_list, rewards_list, next_states_list, dones_list = zip(*batch)\n\n    states = torch.stack(states_list, dim=0)        # (B,H,W,C)\n    next_states = torch.stack(next_states_list,0)   # (B,H,W,C)\n    actions = torch.stack(actions_list)\n    rewards = torch.stack(rewards_list)\n    dones = torch.stack(dones_list)\n\n    return {'blue': states}, actions, rewards, {'blue': next_states}, dones\n\nclass SpatialCNN(nn.Module):\n    def __init__(self, in_channels=5, out_channels=32):\n        super(SpatialCNN, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(16, out_channels, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n    def forward(self, x):\n        # x: (B, C, H, W)\n        return self.conv(x)  # (B, out_channels, H, W)\n\nclass FunctionalPolicyAgent(pl.LightningModule):\n    def __init__(self, action_space_size, embed_dim=5, height=13, width=13, hidden_dim=256, dropout=0.3, epsilon=0.2):\n        super(FunctionalPolicyAgent, self).__init__()\n        self.action_space_size = action_space_size\n        self.epsilon = epsilon\n        self.height = height\n        self.width = width\n        self.hidden_dim = hidden_dim\n        self.dropout = dropout\n\n        # Spatial CNN\n        self.spatial = SpatialCNN(in_channels=embed_dim, out_channels=32)\n\n        # Q-network\n        self.q_network = nn.Sequential(\n            nn.Conv2d(32, 3, kernel_size=1),\n            nn.Flatten(),\n            nn.Linear(height*width*3, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, action_space_size)\n        )\n\n    def forward(self, obs):\n        # obs: (B,H,W,C)\n        obs = obs.permute(0,3,1,2).contiguous()  # (B,C,H,W)\n        spatial_features = self.spatial(obs)  # (B,32,H,W)\n        q_values = self.q_network(spatial_features)\n        return q_values\n\n    def select_action(self, obs, eval_mode=False):\n        if len(obs.shape) == 3:\n            obs = obs.unsqueeze(0)  # (1,H,W,C)\n        if not eval_mode and random.random() < self.epsilon:\n            return random.randint(0, self.action_space_size - 1)\n        with torch.no_grad():\n            q_values = self.forward(obs)\n        return torch.argmax(q_values, dim=-1).item()\n\n    def training_step(self, batch, batch_idx):\n        states, actions, rewards, next_states, dones = batch\n        blue_obs = states['blue']\n        next_blue_obs = next_states['blue']\n        actions = actions\n        rewards = rewards\n        dones = dones\n\n        q_values = self.forward(blue_obs)\n        with torch.no_grad():\n            q_values_next = self.forward(next_blue_obs)\n        max_next_q = q_values_next.max(dim=1)[0]\n        target = rewards + 0.9 * max_next_q * (1 - dones)\n\n        q_values_current = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n        loss = nn.MSELoss()(q_values_current, target)\n        self.log('train_loss', loss)\n        return loss\n\n    def configure_optimizers(self):\n        return optim.Adam(self.parameters(), lr=0.001)\n","metadata":{"papermill":{"duration":7.745247,"end_time":"2024-12-07T05:11:05.496185","exception":false,"start_time":"2024-12-07T05:10:57.750938","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2c746573","cell_type":"code","source":"# 0.005 3 -0.5\n# 0.003 2 -0.2\nenv = battle_v4.env(map_size=45, max_cycles=200, step_reward=0.005, attack_opponent_reward=3, dead_penalty=-0.5)\nreplay_buffer = []\nmax_buffer_size = 10000\nbatch_size = 256\nn_episodes = 100\naction_space_size = 21\nblue_agent = FunctionalPolicyAgent(action_space_size, embed_dim=5, height=13, width=13)\nred_agent = FunctionalPolicyAgent(action_space_size, embed_dim=5, height=13, width=13)\nblue_agent.load_state_dict(torch.load(\"/kaggle/input/rl-parameter/blue_agent_13.pth\"))\n\ntrainer = pl.Trainer(max_epochs=3, devices=2, accelerator='gpu' if torch.cuda.is_available() else 'cpu')\ndevice ='cuda' if torch.cuda.is_available() else 'cpu'\nred_update_interval = 10\nred_agent.load_state_dict(blue_agent.state_dict())\nprev_states = {}\nprev_actions = {}\ndef preprocess_observation(obs, agent_team):\n\n    if agent_team == 'red':\n        return obs[:, ::-1, :].copy() \n    return obs\n\nfor episode in tqdm(range(n_episodes), desc=\"Training episodes\"):\n    env.reset()\n    prev_states.clear()\n    prev_actions.clear()\n\n    done_agents = set()\n    for agent_name in env.agent_iter():\n        obs, reward, termination, truncation, info = env.last()\n        agent_team = agent_name.split('_')[0]\n        done_flag = termination or truncation\n        processed_obs = preprocess_observation(obs, agent_team)\n        if done_flag:\n            action = None\n            done_agents.add(agent_name)\n        else:\n            obs_tensor = torch.tensor(processed_obs, dtype=torch.float32)\n            if agent_team == 'blue':\n                action = blue_agent.select_action(obs_tensor)\n            else:\n                action = red_agent.select_action(obs_tensor)\n\n        if agent_name in prev_states and prev_actions[agent_name] is not None:\n            next_state = obs\n            replay_buffer.append((prev_states[agent_name], prev_actions[agent_name], float(reward), next_state, float(done_flag)))\n            if len(replay_buffer) > max_buffer_size:\n                replay_buffer = replay_buffer[-max_buffer_size:]\n\n        if not done_flag:\n            prev_states[agent_name] = obs\n            prev_actions[agent_name] = action\n        else:\n            # agent done\n            prev_states[agent_name] = obs\n            prev_actions[agent_name] = None\n\n        env.step(action)\n\n    if len(replay_buffer) >= batch_size:\n        dataset = RLReplayDataset(replay_buffer)\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n        trainer  = pl.Trainer(max_epochs=3, devices=2, accelerator='gpu' if torch.cuda.is_available() else 'cpu')\n        trainer.fit(blue_agent, dataloader)\n    if episode % red_update_interval == 0:\n        red_agent.load_state_dict(blue_agent.state_dict())\n\n\ntorch.save(blue_agent.state_dict(), \"blue_agent.pth\")\nprint(\"Model parameters saved.\")\n\nenv.close()","metadata":{"papermill":{"duration":674.757275,"end_time":"2024-12-07T05:22:20.272851","exception":false,"start_time":"2024-12-07T05:11:05.515576","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a5b787b2","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.011322,"end_time":"2024-12-07T05:22:20.325843","exception":false,"start_time":"2024-12-07T05:22:20.314521","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}